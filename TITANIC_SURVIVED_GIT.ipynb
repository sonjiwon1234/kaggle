{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TITANIC_SURVIVED_GIT",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMrl6rUP+hUVY3qOFo8vWiC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonjiwon1234/kaggle/blob/master/TITANIC_SURVIVED_GIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8GJ2O887wNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# set seaborn scheme \n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# set font for graph\n",
        "sns.set(font_scale=2.5) \n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "#ignore warnings\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YYeSTMV8fKP",
        "colab_type": "text"
      },
      "source": [
        "# 1. Check data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf5AyeTg8hvI",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 1.1 read data\n",
        "\n",
        "- using pandas to read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs9SYlhU8btq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#WORK_DIR = '/content'\n",
        "WORK_DIR = '.'\n",
        "df_train = pd.read_csv(WORK_DIR + '/datasets/train.csv')\n",
        "df_test = pd.read_csv(WORK_DIR + '/datasets/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-8KESH58ya9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDqRLMKB8uw0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Features\n",
        "\n",
        "    pclass : 클래스, Integer\n",
        "    age : 나이, Integer\n",
        "    sibsp : 형제와 배우자의 수, Integer\n",
        "    parch : 부모와 아이의 수, Integer\n",
        "    fare : 탑승료, Float\n",
        "    survived : 생존여부, Integer (target label)\n",
        "    embark_town : 출발지\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r7tcnEh815F",
        "colab_type": "text"
      },
      "source": [
        "## <h4>1.2 check null data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCUA5fn_8l8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check null data in train set\n",
        "for col in df_train.columns:\n",
        "    print('column: {:>10}\\t Percent of NULL value: {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum() / df_train[col].shape[0])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dulEJUI988jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check null data in test set\n",
        "for col in df_test.columns:\n",
        "    print('column: {:>10}\\t Percent of NULL value: {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum() / df_test[col].shape[0])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNysZQaY9GGJ",
        "colab_type": "text"
      },
      "source": [
        "# 2. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoFq-vDl9KRo",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.1 Extract title in name\n",
        "- Mr, Mrs, Miss, Master"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U0MwK1Y9M6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Name'].str.extract('([A-Za-z]+)\\.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZG1Nq549OHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Initial']=0\n",
        "for i in df_train:\n",
        "    df_train['Initial']= df_train.Name.str.extract('([A-Za-z]+)\\.') \n",
        "    \n",
        "df_test['Initial']=0\n",
        "for i in df_test:\n",
        "    df_test['Initial']= df_test.Name.str.extract('([A-Za-z]+)\\.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp6fCKZ59PYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ApbbhX9Q52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess',\n",
        "                          'Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n",
        "                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Mr',\n",
        "                       'Mr','Mr','Mr','Mr','Mr', 'Mr'],inplace=True)\n",
        "\n",
        "df_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess',\n",
        "                          'Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n",
        "                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Mr',\n",
        "                       'Mr','Mr','Mr','Mr','Mr', 'Mr'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz2wBo1g9ajG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wJRGbjJ9jQP",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.2 Change Initial to numerical value\n",
        "- Master,Miss, Mr, Mrs, to 0, 1, 2, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouQSsTTc9kBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Initial'] = df_train['Initial'].map(\n",
        "    {'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3})\n",
        "df_test['Initial'] = df_test['Initial'].map(\n",
        "    {'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3})\n",
        "df_train.Initial.unique() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10hO5g_c9o2N",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.3 Family size\n",
        "- sibbs + parch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mgroF4E9m3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 # +1, including  oneself\n",
        "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 # +1, including  oneself"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wersuo_B-bIv",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.4 Fill Embarked\n",
        "- most frequency value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1N2pJmQ-b_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Embarked'].fillna('S', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duw_3b2G-dZ-",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.5 Change Sex to numerical value \n",
        "- female, male to 0, 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QoUtHs9-fIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})\n",
        "df_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yzBkOl4AJdG",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.6 Fare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pyI33ixAG58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NULL값 치환\n",
        "df_train.loc[df_train.Fare.isnull(), 'Fare'] = df_train['Fare'].mean()\n",
        "df_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean()\n",
        "\n",
        "df_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i>0 else 0)\n",
        "df_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i>0 else 0)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "g = sns.distplot(df_train['Fare'], color='b', \n",
        "            label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\n",
        "g = g.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPspPvTEAVDP",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.7 Fill Age\n",
        "- regression imputation \n",
        "- Mean imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjoeq6ghAV4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regression imputation\n",
        "\n",
        "# from sklearn.experimental import enable_iterative_imputer\n",
        "# from sklearn.impute import IterativeImputer\n",
        "# from sklearn.linear_model import BayesianRidge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkkRyIn6AsZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imp = IterativeImputer(max_iter=10, verbose=0)\n",
        "# imp.fit(df_train_age)\n",
        "# imputed_df_train = imp.transform(df_train_age)\n",
        "# imputed_df_train = pd.DataFrame(imputed_df_train, columns=df_train_age.columns)\n",
        "\n",
        "# #imp = IterativeImputer(max_iter=10, verbose=0)\n",
        "# imp.fit(df_test_age)\n",
        "# imputed_df_test = imp.transform(df_test_age)\n",
        "# imputed_df_test = pd.DataFrame(imputed_df_test, columns=df_test_age.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgA43EoLAyQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mean imputation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfk8KD4RA3yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all = pd.concat([df_train, df_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcwxLeDmA4SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tY5h9BwA5Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "age_median = df_all.groupby(['Initial', 'Pclass'])['Age'].agg(['median'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkbmuG6FA7QZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "age_median = age_median.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAEwGdbcA8O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index in df_train[df_train.Age.isnull()].index:\n",
        "  median = age_median[(age_median.Initial == df_train.iloc[index]['Initial']) &\n",
        "                      (age_median.Pclass == df_train.iloc[index]['Pclass'])\n",
        "                      ]['median'].values[0] \n",
        "  df_train.at[index, 'Age'] = median  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyRTPs8WA_DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index in df_test[df_test.Age.isnull()].index:\n",
        "  median = age_median[(age_median.Initial == df_test.iloc[index]['Initial']) &\n",
        "                      (age_median.Pclass == df_test.iloc[index]['Pclass'])\n",
        "                      ]['median'].values[0] \n",
        "  df_test.at[index, 'Age'] = median  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQGh5f-JBA5B",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.8 Change Age to Categorical value\n",
        "- Divide into 6 sections\n",
        "- 0 ~ 4 / 5 ~ 11 / 12 ~ 17 / 18 ~ 35 / 36 ~ 56 / 56 ~ 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzxKlTUoBAPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #df_train['Age_cat'] = 0\n",
        "df_train.loc[df_train['Age'] < 5, 'Age_cat'] = 0 # babies\n",
        "df_train.loc[(5 <= df_train['Age']) & (df_train['Age'] < 12), 'Age_cat'] = 1 # children\n",
        "df_train.loc[(12 <= df_train['Age']) & (df_train['Age'] < 18), 'Age_cat'] = 2 # teen\n",
        "df_train.loc[(18 <= df_train['Age']) & (df_train['Age'] < 36), 'Age_cat'] = 3 # young adulthood\n",
        "df_train.loc[(36 <= df_train['Age']) & (df_train['Age'] < 56), 'Age_cat'] = 4 # middle age\n",
        "df_train.loc[56 <= df_train['Age'], 'Age_cat'] = 5 # older adulthood\n",
        "\n",
        "#df_test['Age_cat'] = 0\n",
        "df_test.loc[df_test['Age'] < 5, 'Age_cat'] = 0 # babies\n",
        "df_test.loc[(5 <= df_test['Age']) & (df_test['Age'] < 12), 'Age_cat'] = 1 # children\n",
        "df_test.loc[(12 <= df_test['Age']) & (df_test['Age'] < 18), 'Age_cat'] = 2 # teen\n",
        "df_test.loc[(18 <= df_test['Age']) & (df_test['Age'] < 36), 'Age_cat'] = 3 # young adulthood\n",
        "df_test.loc[(36 <= df_test['Age']) & (df_test['Age'] < 56), 'Age_cat'] = 4 # middle age\n",
        "df_test.loc[56 <= df_test['Age'], 'Age_cat'] = 5 # older adulthood"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwQ74lGRBYsq",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.9 one-hot encoding\n",
        "using pandas.get_dummies()\n",
        "- Initial \n",
        "- Embarked\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ9M1ApZBWjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_encoding = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')\n",
        "df_test_encoding = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')\n",
        "\n",
        "df_train_encoding.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZvZkDrpBaw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_encoding = pd.get_dummies(df_train_encoding, columns=['Embarked'], prefix='Embarked')\n",
        "df_test_encoding = pd.get_dummies(df_test_encoding, columns=['Embarked'], prefix='Embarked')\n",
        "\n",
        "df_train_encoding.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr-Rx60WBcdy",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 2.10 Drop columns\n",
        "Drop unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAdVgzrRBRnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_encoding.drop(['PassengerId', 'Name', 'Age','SibSp', 'Parch', 'Ticket', 'Cabin','Fare'], axis=1, inplace=True)\n",
        "df_test_encoding.drop(['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Cabin','Fare'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIbKNsFkBgS7",
        "colab_type": "text"
      },
      "source": [
        "# 3. Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCU6vgIzBiVB",
        "colab_type": "text"
      },
      "source": [
        "## <h4>3.1 Set dataset\n",
        "using train_test_split()\n",
        "- split data into train, valid and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl28CDJ1Bkev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80H157loBm9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습에 쓰일 데이터와 target label 분리\n",
        "X_train = df_train_encoding.drop('Survived', axis=1).values\n",
        "target_label = df_train_encoding['Survived'].values\n",
        "X_test = df_test_encoding.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR3PEWrKBoNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.2, random_state=2018, stratify = target_label)\n",
        "X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.2, random_state=2018)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-4O6zEZHMDn",
        "colab_type": "text"
      },
      "source": [
        "train_test_split(.., stratify = )  \n",
        "- use stratify can get good score in kaggle public section with 0.80382 score\n",
        "- but bad score in private section  \n",
        "\n",
        "- My think is that i use stratify for avoid class imbalance problem, but this driven overfitting problem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dat9OHmZDYku",
        "colab_type": "text"
      },
      "source": [
        "## <h3> 3.2 Modeling\n",
        "- random forest with GridSearchCV\n",
        "- nn with voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfLaM9GMDqQ5",
        "colab_type": "text"
      },
      "source": [
        "### <h4> 3.2.1 random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WvT01CyBqBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hz0inZ5DsVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyper-parms tuning\n",
        "\n",
        "params = { 'n_estimators' : [10, 100, 200, 400],\n",
        "           'max_depth' : [10, 20, 30, None],\n",
        "           'min_samples_leaf' : [1,2,4],\n",
        "           'min_samples_split' : [2,5,10]\n",
        "            }\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state = 42)\n",
        "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 3, n_jobs = -1)\n",
        "grid_cv.fit(X_train, target_label)\n",
        "\n",
        "print('best parms: ', grid_cv.best_params_)\n",
        "print('best score: {:.4f}'.format(grid_cv.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjI7y9scDt71",
        "colab_type": "text"
      },
      "source": [
        "- best parms:  {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
        "- best score : 0.8373"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hy0Q4RcD90e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training\n",
        "\n",
        "rfmodel = RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100)\n",
        "rfmodel.fit(X_tr, y_tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_deKk6EAge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict\n",
        "rfprediction = rfmodel.predict(X_vld)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6f_6hh_EG-G",
        "colab_type": "text"
      },
      "source": [
        "###<h4>3.2.2 NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvRTtq-REDc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense , Dropout, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasClassifier \n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.optimizers import rmsprop\n",
        "import random "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYdiwJVHEJGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model( lr = 0.001, opt = 'RMSprop', init = 'he_normal', dr = 0.2): # create model \n",
        "\n",
        "  # fix random seed for reproducibility\n",
        "  seed = 42 \n",
        "  random.seed(seed)\n",
        "\n",
        "  model = Sequential() \n",
        "  \n",
        "  model.add(Dense(32, input_dim=X_train.shape[1], activation='relu', kernel_initializer =init)) \n",
        "  model.add(Dropout(dr))\n",
        "  #for i in range(1, len(lyrs)):\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  \n",
        "  model.add(Dense(1, activation='sigmoid')) \n",
        "\n",
        "  opt= rmsprop(lr=lr)\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) \n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHp1tiT4EKoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using Grid Search to optimize hyper-parms\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "epochs = [50,100,150,300, 400] ##// increase epochs        \n",
        "batches = [1, 16, 32, 64]\n",
        "\n",
        "param_grid = dict(epochs=epochs, batch_size=batches)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_tr, y_tr)                                                                                                                                    \n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score'] \n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95G_DSWTEON0",
        "colab_type": "text"
      },
      "source": [
        "-  Best: 0.833905 using {'batch_size': 32, 'epochs': 300}\n",
        "  - 0.832663 (0.027716) with: {'batch_size': 16, 'epochs': 400}\n",
        "  - 0.832655 (0.028021) with: {'batch_size': 1, 'epochs': 100} \n",
        "  - 0.830171 (0.025037) with: {'batch_size': 64, 'epochs': 150}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csldp8NhENz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_size = 300\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueNVVQHqEQ9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using Grid Search to optimize hyper-parms\n",
        "model = KerasClassifier(build_fn=create_model,epochs=epoch_size, batch_size=batch_size ,verbose=0)\n",
        "\n",
        "optimizers = ['rmsprop','adam','Adadelta']\n",
        "init = ['glorot_uniform', 'he_normal']\n",
        "\n",
        "param_grid = dict(opt=optimizers, init=init)                                                                                                                                 \n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_tr, y_tr)   \n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score'] \n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghJudw35ETuH",
        "colab_type": "text"
      },
      "source": [
        "- Best: 0.833905 using {'init': 'he_normal', 'opt': 'rmsprop'}\n",
        "  - 0.830163 (0.027448) with: {'init': 'glorot_uniform', 'opt': 'adam'}\n",
        "  - 0.830155 (0.029660) with: {'init': 'glorot_uniform', 'opt': 'Adadelta'}\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eSDT0wBESnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using Grid Search to optimize hyper-parms\n",
        "model = KerasClassifier(build_fn=create_model,epochs=epoch_size, batch_size=batch_size ,verbose=0)\n",
        "\n",
        "drops = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "param_grid = dict(dr = drops)                                                                                                                                 \n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_tr, y_tr)   \n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score'] \n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MwH3Ks9EWIX",
        "colab_type": "text"
      },
      "source": [
        "Best: 0.824426 using {'dr': 0.2}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wDBb9KsEY75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnmodel = KerasClassifier(build_fn=create_model, epochs=epoch_size, batch_size=batch_size, verbose=0) #, validation_split=0.1) # without validation split # not enough dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0LoWT4EcoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "accuracies =  cross_val_score(estimator=nnmodel, X= X_tr, y=y_tr, cv=10, n_jobs=-1)\n",
        "accuracies\n",
        "accuracies.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2stPoVyEiKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = nnmodel.fit(X_tr, y_tr, callbacks = [])\n",
        "nnprediction = nnmodel.predict(X_vld)\n",
        "nnprediction = nnprediction.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4kE7dzgEjZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kop6FHdTEkUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(1)\n",
        "for l in acc_list:\n",
        "    plt.plot(range(epoch_size), history.history[l], 'b')\n",
        "for l in val_acc_list:\n",
        "    plt.plot(range(epoch_size), history.history[l], 'g')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "\n",
        "plt.figure(2)\n",
        "for l in loss_list:\n",
        "    plt.plot(range(epoch_size), history.history[l], 'b')\n",
        "for l in val_loss_list:\n",
        "    plt.plot(range(epoch_size), history.history[l], 'g')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuTT6QAZGHTo",
        "colab_type": "text"
      },
      "source": [
        "#### - Voting with nn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGMPZSb1Ep8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nnmodel = KerasClassifier(build_fn=create_model, epochs=epoch_size, batch_size=batch_size, verbose=0)\n",
        "nnmodel1 =  KerasClassifier(build_fn=create_model, epochs=epoch_size, batch_size=batch_size, verbose=0)\n",
        "nnmodel1._estimator_type=\"classifier\"\n",
        "nnmodel2 =  KerasClassifier(build_fn=create_model, epochs=400, batch_size=16, verbose=0)\n",
        "nnmodel2._estimator_type=\"classifier\"\n",
        "nnmodel3 =  KerasClassifier(build_fn=create_model, epochs=100, batch_size=1, verbose=0)\n",
        "nnmodel3._estimator_type=\"classifier\"\n",
        "nnmodel4 =  KerasClassifier(build_fn=create_model, epochs=150, batch_size=64, verbose=0)\n",
        "nnmodel4._estimator_type=\"classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8y8ZRDLGKPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vcnnmodel = VotingClassifier(estimators = [('model1',nnmodel1),('model2',nnmodel2),('model3',nnmodel3),('model4',nnmodel4)], voting = 'hard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emt6tA92GL4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vcnnmodel.fit(X_tr, y_tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2lOgjueGNE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vcnnprediction = vcnnmodel.predict(X_vld)\n",
        "vcnnprediction = vcnnprediction.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO6cp1htGSuh",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 3.3 Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAS1Y5z6GUKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy\n",
        "rfacc = 100 * metrics.accuracy_score(rfprediction, y_vld)\n",
        "print('randomforest acc :  {:.2f}% '.format(rfacc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z122qc8GbPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy\n",
        "nnacc = 100 * metrics.accuracy_score(nnprediction, y_vld)\n",
        "print('NN acc : {:.2f}% '.format( nnacc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UofHLIGfYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy\n",
        "vcnnacc = 100 * metrics.accuracy_score(vcnnprediction, y_vld)\n",
        "print('Voting(NN) acc : {:.2f}% '.format( vcnnacc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0mkBOwRGkTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accres = pd.Series([rfacc,nnacc, vcnnacc], index = ['Random Forest', 'NN', 'Voting(NN)'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLvC_B8G1-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.xlim(82,accres.max())\n",
        "accres.sort_values(ascending=True).plot.barh()\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x4ltuRoG3FM",
        "colab_type": "text"
      },
      "source": [
        "## <h4> 3.5 Save result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD32TCuoG2ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#WORK_DIR = '/content'\n",
        "WORK_DIR = '.'\n",
        "submission = pd.read_csv(WORK_DIR + '/datasets/sample_submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_loRnuXG5sN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_prediction = rfmodel.predict(X_test)\n",
        "submission['Survived'] = res_prediction\n",
        "submission.to_csv('./baseline_submission_vc.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}